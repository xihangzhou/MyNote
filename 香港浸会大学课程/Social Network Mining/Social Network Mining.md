# Social Network Mining

@(é¦™æ¸¯æµ¸ä¼šå¤§å­¦)

## Network Measures
### 1.NodeInfluence/Centrality
ç»“ç‚¹å½±å“åŠ›
#### 1.1ç”¨é‚»å±…å†³å®š
##### 1.1.1Degree Centrality
* ç”¨å‡ºåº¦å…¥åº¦æ¥å®šä¹‰Centrality
* ***ä¸‰ç§è®¡ç®—Normalized Degree Centralityçš„æ–¹å¼P14***
##### 1.1.2 Eigenvector Centrality
è¢«æ›´é‡è¦çš„æœ‹å‹æŒ‡å‘åˆ™æ›´é‡è¦
![Alt text](./1588574570648.png)
å¯ä»¥ç”¨Eigendecompositionæ±‚è§£
##### 1.1.3 PageRank
ä¸€ä¸ªäººçš„å‡ºåº¦è¶Šå¤šï¼Œé‚£ä¹ˆä»–çš„æŒ‡å‘ä¹Ÿè¶Šä¸é‡è¦
![Alt text](./1588574774530.png)
***Power Iteration Methodè®¡ç®—ï¼Œç”¨äºè§£å†³å¤§çŸ©é˜µeigenåˆ†è§£ä¸äº†çš„é—®é¢˜P37***
***Damping Factorè§£å†³å‡ºåº¦ä¸º0çš„é—®é¢˜***
***Redistributing to all nodesè§£å†³å‡ºåº¦ä¸º0çš„é—®é¢˜P45***
#### 1.2ç”¨æ€ä¹ˆåˆ°è¾¾å…¶ä»–ç»“ç‚¹å†³å®š
##### 1.2.1Betweenness Centrality
***Normalizingçš„è®¡ç®—P50 51***
##### 1.2.1Closeness Centrality
***è®¡ç®—P53 P54***
#### 1.3ç»„çš„centrality
å°±æ˜¯æŠŠå‡ ä¸ªnodeçœ‹æˆä¸€ä¸ªnodeå’Œä¸Šé¢è®¡ç®—æ–¹æ³•ç›¸åŒ
***Group degree/betweenness/closeness centralityè®¡ç®—P59***
### 2.Node Interaction
ç»“ç‚¹ä¹‹é—´å…³ç³»
#### 2.1 Transitivity
è¡¡é‡è¿™ä¸ªå›¾çš„ä¼ é€’æ€§
##### 2.1.1 Clustering Coefficient
è¡¡é‡æ— å‘å›¾ä¸­çš„ä¼ é€’æ€§
***P63è®¡ç®—***
##### 2.1.2 Local Clustering Coefficient
***è®¡ç®—P64P65***
#### 2.2 Balance and status
##### 2.2.1 Social Balance Theory
æ»¡è¶³è´Ÿè´Ÿå¾—æ­£çš„ç¯çš„å›¾P68
##### 2.2.2 Social Status Theory
A>B A>C => A>C
æ»¡è¶³è¯¥å¼ä¸ºstableå¦åˆ™ä¸stable
P70
#### 2.3 Similarity
ç»“ç‚¹ä¹‹é—´ç›¸ä¼¼åº¦ï¼Œç”¨å…±åŒæœ‹å‹å®šä¹‰
##### Structural Equivalence
* Vertex similarity
* Jaccard Similarity
* Cosine Similarity
***æ¯ä¸€ç§çš„è®¡ç®—P73 74***
## Community Analysis
### 1.ä»€ä¹ˆæ˜¯Community Analysis
Community Detection vs. Clustering P11 12
### 2. Member-based Community Detection
#### 2.1Node Degreeåˆ†Community
##### 2.1.1 Clique
Clique:ä»»æ„ä¸¤ç‚¹å¯ä»¥ç›´æ¥åˆ°è¾¾çš„å›¾
Maximal Clique:ä¸èƒ½å†expandçš„Clique
Maximum Clique:æœ€å¤§çš„Maximal Clique
##### 2.1.2 Clique of size k
Clique of size kï¼šcliqueä¸­æ¯ä¸ªç»“ç‚¹çš„åº¦éƒ½å¤§äºç­‰äºk-1ï¼Œå³sizeä¸ºkçš„clique
***æ‰¾Clique of size k P23***
##### 2.1.3 Relaxing Cliques
* k-plex: æ‰€æœ‰ç»“ç‚¹çš„åº¦å¤§äºç­‰äº |V| - k(åªçœ‹è¿™ä¸ªå­å›¾ä¸­çš„éƒ¨åˆ†) |V|å­—å›¾ä¸­çš„ç»“ç‚¹ä¸ªæ•°
***æ‰¾maximal k-plex P25 26***

* k-core:å­å›¾ä¸­æ‰€æœ‰ç»“ç‚¹åº¦è‡³å°‘ä¸ºk
* k-shellï¼š åœ¨k-coreä¸­ä½†ä¸åœ¨k+1-coreä¸­
***è®¡ç®—çœ‹ä½œä¸š***
##### 2.1.3 CPM
***ç”¨CPMæ‰¾communitiesP31***
#### 2.1Node Reachabilityåˆ†Community
* k-clique: åŸºäºåŸå›¾ä»»æ„ä¸¤ç‚¹æœ€çŸ­è·ç¦»ä¸è¶…è¿‡kçš„maximalçš„å­å›¾ä¸ºä¸€ä¸ªcommunity
* k-clan:å…ˆæ˜¯k-clique,å†å»æ‰k-cliqueä¸­åˆ©ç”¨äº†å¤–ç»“ç‚¹çš„
* k-Club: åŸºäºå­å›¾ä»»æ„ä¸¤ç‚¹æœ€çŸ­è·ç¦»ä¸è¶…è¿‡kçš„maximalçš„å­å›¾ä¸ºä¸€ä¸ªcommunity
***æ‰¾è¿™ä¸‰ä¸ªP33***
#### 2.3 Node Similarityåˆ†Community
Structural Equivalenceè®¡ç®—ç›¸ä¼¼åº¦å†ç”¨clusteringçš„æ–¹æ³•åˆ†
### 3.Group-basedCommunityDetection
#### 3.1 Balanced Communities
Minimum cut (min-cut) problemå¯¼è‡´ä¸å¹³è¡¡çš„ç¤¾åŒº
ç”¨***Ratio Cut & Normalized Cut çš„è®¡ç®— P40***
##### 3.1.1 Spectral Clustering
$ X^{T}AX$çš„diagonalæ˜¯æ¯ä¸€ä¸ªcommunityä¸­çš„æ¯ä¸€ä¸ªç‚¹çš„è¾¹æ•°å’Œ
$ X^{T}DX$çš„diagonalæ˜¯æ¯ä¸€ä¸ªcommunityä¸­çš„æ¯ä¸€ä¸ªç‚¹çš„è¾¹æ•°å’Œä¸ç®—è¢«cutçš„è¾¹
$ X^{T}(D-A)X$çš„diagonalæ˜¯cutæ‰çš„è¾¹æ•°
#### 3.2 Robust Communities
* k-vertex connected(k-connected) graph:è‡³å°‘ç§»é™¤kä¸ªç‚¹è®©è¿™ä¸ªå›¾ä¸è¿é€š
* k-edge connected: è‡³å°‘ç§»é™¤kæ¡è¾¹è®©è¿™ä¸ªå›¾ä¸è¿é€š
#### 3.3 Modular Communities
ä¸¤ä¸ªç»“ç‚¹å·²çŸ¥åº¦ï¼Œä¸çŸ¥å…·ä½“çš„è¾¹æ•°ï¼Œè®¡ç®—éšæœºè¾¹æ•°ï¼š![Alt text](./1588583372312.png)
å¯¹ä¸€ä¸ªpartitionä¸­çš„ä¸€éƒ¨åˆ†çš„Normalized Modularity:
![Alt text](./1588583425322.png)(è¶Šå¤§è¶Šæœ‰æ¨¡å—æ€§)
å¯¹ä¸€ä¸ªpartitionçš„ Modularityï¼š
![Alt text](./1589079661343.png)
å¯¹ä¸€ä¸ªpartitionçš„**Normalized** Modularity:
![Alt text](./1588583477071.png)
***ä¼šè®¡ç®—Normalized Modularity***
**æœ€åmodularityæœ€å¤§çš„partitionä½œä¸ºæœ€åçš„communityçš„åˆ’åˆ†æ–¹å¼**
# Web Usage Mining
ç”¨clickstreamåˆ†æusers
## 1.Clickstream Data Pre-Processing
P13è¦cleançš„records
### 1.1User Identification and User Session
sessionå¯¹åº”ä¸€ä¸ªç”¨æˆ·çš„ä¸€æ¬¡è®¿é—®
é€šè¿‡sessionè¾¨è®¤ç”¨æˆ·èº«ä»½
***ç›¸åŒIPåœ°å€åˆ¤å®šä¸ºåŒä¸€ç”¨æˆ·P15 16***
### 1.2 Sessionization and Transaction Identification
#### 1.2.1Sessionization
åŒä¸€IPåœ°å€ç»§ç»­åˆ’åˆ†sessionçš„ä¸¤ç§æ–¹æ³•
* time-oriented heuristics
* h-ref heuristics
***P20 21***
#### 1.2.2 User Transaction Identification
userçš„sessionå¯ä»¥æ ¹æ®ä¸åŒçš„æ´»åŠ¨è¢«åˆ†ä¸ºä¸åŒçš„transaction,transactionå¯ä»¥è¢«åˆ†ä¸ºä¸¤ç±»ï¼š
* Auxiliary-content transactionsï¼šfor navigation
* Content-only transactions:ä¸ºäº†æŸä¸€ç›®çš„æµè§ˆé¡µé¢
#### 1.2.3 Transaction Matrix
![Alt text](./1589080432582.png)
å¯ä»¥å¯¹è¿™ä¸ªçŸ©é˜µè¿›è¡ŒååŒè¿‡æ»¤ç­‰æ–¹æ³•åˆ†æ
## 2. Clickstream Data Analysis
### 2.1Sequential Pattern Analysis
***æ ¹æ®ç”¨æˆ·transactionæ„å»ºMarkov Chain P36***
### 2.2 Web Usage Regularity Characterization
#### 2.2.1 Scale-free Network
åº¦ä¸º kçš„ç»“ç‚¹ä¸ªæ•°æ»¡è¶³power lawï¼š
![Alt text](./1588586458271.png)
large-scalseçš„ç½‘ç»œéƒ½æ»¡è¶³power law
#### 2.2.2 Characterization of Web Usage
å¦å¤–ä¸¤ä¸ªæŒ‡æ ‡ä¹Ÿåœ¨å¤§å‹ç½‘ç»œä¸­æ»¡è¶³power law:
* Forging depth (how long they search)
* Link-click frequency (how frequent a link is clicked)
***ç”¨è¿™ä¸¤ä¸ªæŒ‡æ ‡æ¥åˆ¤æ–­ç”¨æˆ·æ˜¯recurrentè¿˜æ˜¯rationalP44 45*** 
rå€¼è¶Šå¤§ï¼Œç›¸åŒåº¦çš„ç»“ç‚¹è¶Šå°‘ï¼Œè¶Šrational,åä¹‹è¶Šrecurrent

# Opinion Mining and Sentiment Analysis
## 1.Key Tasks in Opinion Mining
### 1.1 Opinion Representation
opinion is a quintuple
* entity å®ä½“
* aspect å®ä½“çš„æŸä¸€ä¸ªæ–¹é¢ 
* orientation æ­£é¢è¿˜æ˜¯è´Ÿé¢
* opinion holder
* time when the opinion is expressed
***æå–opinion P12-19***
## 2.POS Tagging
è¯­æ³•æ ‡è®°
### 2.1Rule-based POS Tagging
***ç”¨å·²æœ‰POSæ ‡è®°çš„è¯åº“å’Œparch ruleçš„ç»„åˆå»æ ‡è®°POS P26-27***
## 3.Entity/Aspect Extraction
è®¾è®¡Extraction Ruleså®šä½entityå’Œaspect
ä¸¤ç§æ–¹å¼ï¼š
* ç›´æ¥æ‰¾å¯¹åº”çš„å•è¯
* æ‰¾å‰åçš„å½¢å®¹è¯ç­‰
### 3.1 Obtain Extraction Rules
#### 3.1.1 Unsupervised Aspect Extraction
ç”¨å¸¸è§çš„aspectæ¨å‡ºä¸å¸¸è§çš„
***æå–aspectçš„unsupervisedæ–¹æ³•P36***
#### 3.1.1 Supervised Aspect Extraction
äººå·¥æ ‡è®°training dataç”ŸæˆHidden Markov Modelï¼Œå¯¹åº”è¾“å…¥çš„å¥å­å»æ‰¾ä¸€æ¡joint probabilityæœ€å¤§çš„path,è¿™æ¡pathä¸­çš„Aå°±æ˜¯è¿™ä¸ªå¥å­ä¸­çš„aspect
***è¦ä¼šè®¡ç®—P44***
## 4.Aspect Sentiment Classification
åˆ†ç±»ä¸»å®¢è§‚è¯„ä»·å’Œä¸»è§‚è¯„ä»·ä¸­ç§¯æè´Ÿé¢ä¸­æ€§è¯„ä»·
* Supervised Method
æœ‰æ ‡è®°åˆ™ç›´æ¥ç”¨æ ‡è®°
* Unsupervised Method
æ‰¾extraction patterns å’Œ subjective words
### 4.1æå–extraction patterns
***P54***
### 4.2åˆ›å»ºæ–°çš„subjective words/Opinion Lexicon
æ–¹æ³•1:
***lexicon-based approach P55***
æ–¹æ³•2:
***è®¡ç®—PMIæ¯”è¾ƒè¯è¯­çš„ç›¸ä¼¼åº¦ä»è€Œä»å·²çŸ¥åå‘çš„è¯å‡ºå‘æ¨æ–­ä¸€ä¸ªè¯çš„å€¾å‘æ€§(åpositive or negative)57-P59***
### 4.3 æ³¨æ„
* å®¢è§‚çš„å¥å­ä¹Ÿå¯ä»¥è¡¨è¾¾ä¸»è§‚çš„æ„Ÿå—ï¼Œå¦‚The earphone broke in two days
* æƒ…ç»ªemotionå’Œopinionsçœ‹æ³•è§‚ç‚¹å¹¶ä¸å®Œå…¨åˆ’ç­‰å·

# è¡¥ä¸
## 1. Eigendecomposition
è¦ä¼šè®¡ç®—å¯¹ç§°çŸ©é˜µçš„ç‰¹å¾å€¼åˆ†è§£
![Alt text](./1589007420983.png)
![Alt text](./1589007434316.png)
![Alt text](./1589007448040.png)

## 2.å¯¹PCAçš„å¤§è‡´ç†è§£
### 2.1ç†è§£è®¡ç®—PCAçš„æ­¥éª¤
![Alt text](./1589008511941.png)

* center the dataå³æ¯ä¸ªç‚¹çš„æ¯ä¸€ç»´å‡å»è¯¥ç»´çš„æ‰€æœ‰ç‚¹çš„å¹³å‡å€¼
* è®¡ç®—è¯¥çŸ©é˜µçš„åæ–¹å·®çŸ©é˜µ
* ç”±äºè¯¥åæ–¹å·®çŸ©é˜µä¸ºå¯¹ç§°çŸ©é˜µçŸ©é˜µï¼Œå¯ä»¥ç›´æ¥eigendecomposition
* ä¿ç•™kä¸ªæœ€å¤§çš„eigenvectorå¯¹åº”çš„eigenvalueç»„æˆU
* æœ€åXUç›¸ä¹˜å¾—åˆ°é™ä¸ºkç»´åçš„çŸ©é˜µ
### 2.2 PCAçš„æ„ä¹‰
Transforming (also called projecting) the original coordinate system (or space) to another one so that the different dimensions in the new coordinate system are linearly uncorrelated.
æŠ•å½±åŸåæ ‡ç³»åˆ°æ–°çš„çº¿å½¢ä¸æƒ³å…³çš„åæ ‡ç³»å¹¶è®©ç‚¹çš„æ–¹å·®æœ€å¤§


## 3.åæ–¹å·®çŸ©é˜µ
### 3.1åæ–¹å·®å‘é‡
![Alt text](./1589009757341.png)
* cov(x,y)=0è¿™ä¸¤ä¸ªå˜é‡ç‹¬ç«‹
### 3.2åæ–¹å·®çŸ©é˜µ
![Alt text](./1589009385731.png)
* ![Alt text](./1589012851962.png)   ä¸€ä¸ªçŸ©é˜µå’Œå…¶åæ–¹å·®çŸ©é˜µçš„å…³ç³»
* è‹¥nç»´çº¿å½¢ä¸ç›¸å…³ï¼ŒCov(X)ä¼šæ˜¯ä¸€ä¸ªdiagonal matrix
### 3.3å’ŒPCAçš„è”ç³»
* å®é™…ä¸Š![Alt text](./1589009450605.png)   å°±æ˜¯PCAä¸­å¯¹æ‰€æœ‰ç‚¹å±…ä¸­çš„è¿‡ç¨‹
* ![Alt text](./1589009926696.png)
![Alt text](./1589009997879.png)    ä¹Ÿå°±æ˜¯ä¸€ä¸ªnç»´ç‹¬ç«‹çš„çŸ©é˜µï¼Œæ‰€ä»¥first k principle component vectorsä»ç„¶ç‹¬ç«‹

## 4.SVDåŠLatent Semantic Analysis
### 4.1 SVD
![Alt text](./1589011598884.png)
![Alt text](./1589011303817.png)    ![Alt text](./1589011335090.png)
æ³¨æ„U=![Alt text](./1589011706037.png)
### 4.2 Latent Semantic Analysis
ä½¿ç”¨äº†SVDå¯¹TF-IDFçŸ©é˜µåšå¤„ç†ï¼Œè§£å†³å¦‚ä¸‹é—®é¢˜ï¼š
â€¢ Small storage (dimension reduction)
â€¢ Remove noise in document-term matrix
â€¢ Recover missing data via the help of co-occurrence patterns (addressed the sparsity problem)
æœ€ç»ˆä½¿å¾—ç›¸è¿‘çš„ç‚¹æ›´ç›¸è¿‘ï¼Œè¿œçš„ç‚¹æ›´è¿œï¼Œè§£å†³ä¸€ä¹‰å¤šè¯çš„é—®é¢˜
ä¸è€ƒè™‘è¯ä¹‹é—´çš„é¡ºåºé™¤éçŸ©é˜µä½¿ç”¨äº†n-gramæ¨¡å‹
**ä¾‹å­ï¼š**
![Alt text](./1589011883409.png)
![Alt text](./1589011893747.png)
![Alt text](./1589011945183.png)
![Alt text](./1589011957123.png)
![Alt text](./1589011972070.png)
![Alt text](./1589011983722.png)
![Alt text](./1589011994406.png)
![Alt text](./1589012004033.png)
## 5.word2vec
![Alt text](./1589012284684.png)
* ä¸LSAæ½œåœ¨è¯­ä¹‰åˆ†æä¸åŒçš„æ˜¯LSAè€ƒè™‘çš„æ˜¯æ•´ä¸ªdocumentçš„co-occurence patternä½†æ˜¯word2vecè€ƒè™‘çš„æ˜¯local neighborhoodçš„co-occurence pattern.
* è€ƒè™‘äº†ä¸Šä¸‹æ–‡contextçš„å½±å“è¿›è¡Œword embedding,ä»è€Œå¯ä»¥é¢„æµ‹ä¸€ä¸ªè¯çš„ä¸Šä¸‹æ–‡
* å¦‚æœæ˜¯ç”¨ä¸€ä¸ªè¯è¯­ä½œä¸ºè¾“å…¥ï¼Œæ¥é¢„æµ‹å®ƒå‘¨å›´çš„ä¸Šä¸‹æ–‡ï¼Œé‚£è¿™ä¸ªæ¨¡å‹å«åšã€Skip-gram æ¨¡å‹ã€
è€Œå¦‚æœæ˜¯æ‹¿ä¸€ä¸ªè¯è¯­çš„ä¸Šä¸‹æ–‡ä½œä¸ºè¾“å…¥ï¼Œæ¥é¢„æµ‹è¿™ä¸ªè¯è¯­æœ¬èº«ï¼Œåˆ™æ˜¯ ã€CBOW æ¨¡å‹ã€
* ![Alt text](./1589012647874.png)
é€šè¿‡æœ€å¤§åŒ–ä¸Šä¸‹æ–‡çš„joint probabilityæ¥word embedding
## 6.n-gramå’Œbigram
* The general case is ğ‘›-gram model, where the ğ‘› th term is conditioned on the previous ğ‘› âˆ’ 1 terms
* bigramå°±æ˜¯ä¸¤ä¸¤ç»„åˆï¼Œéœ€è¦é€šè¿‡Chi-Square Testæ¥è¿›è¡Œæœ‰æ•ˆç­›é€‰
* bigramæœ€å¤šæœ‰Vçš„å¹³æ–¹ä¸ª
![Alt text](./1589013591675.png)
* è¿™ç§æ–¹å¼è€ƒè™‘äº†ä¸Šä¸‹æ–‡ï¼Œæ›´ç²¾ç¡®ï¼Œå¹¶ä¸”å¯ä»¥ç»™ä¸€ä¸ªè¯é¢„æµ‹å®ƒçš„ä¸Šä¸‹æ–‡
## 7.Skip-gram Model
![Alt text](./1589014031129.png)
ä¼šæ‰¾skip-gramå³å¯ï¼Œä¹Ÿæ˜¯è€ƒè™‘äº†ä¸Šä¸‹æ–‡ï¼Œå¹¶ä¸”å¯ä»¥ç»™ä¸€ä¸ªè¯é¢„æµ‹å®ƒçš„ä¸Šä¸‹æ–‡
## 8.topic model
### 8.1å‡è®¾
* Considering documents to be independent of each other is a strong assumption.
* Documents under similar topics should have a similar set of words (instead of independent).
* ç»™å®štopic,queryå’Œdocç‹¬ç«‹
### æ€æƒ³
â€¢ Each topic is a distribution over words.
â€¢ Each document is a mixture of corpus-wide topics. 
â€¢ Each word is drawn from one of those topics.
### 8.2æ ¹æ®topic modelè®¡ç®—æ¦‚ç‡å’Œranking
![Alt text](./1589017133331.png)
### 8.3topic modelçš„è°ƒæ•´
![Alt text](./1589017264567.png)
å³è¾¹æ›´å¥½å› ä¸ºå³è¾¹çš„åŒºåˆ«æ›´å¤§ï¼Œæ›´æ˜“åŒºåˆ†topicå’Œè§£é‡Š
é€šè¿‡è°ƒæ•´ğœ¶ and ğœ¼ä½¿å¾—åˆ†éƒ¨æ›´æç«¯è·å¾—
ğœ¶ and ğœ¼è¶Šæ¥è¿‘0è¶Šæç«¯ï¼Œè¶Šæ¥è¿‘1åˆ†éƒ¨è¶Šå‡åŒ€
æ‰€ä»¥ğœ¶ and ğœ¼è¶Šæ¥è¿‘0è¶Šå¥½
### 8.4ä¼˜åŠ¿
topic model assumes that the online news share a common set of topics, and each topic is associated with the set of words from different documents but discovered to be under the same topic. This leads to better retrieval results.
å› ä¸ºtopic modelå‡è®¾äº†ç›¸è¿‘è¯å±äºä¸€ä¸ªtopic,ä¸€ä¸ªæ–‡ä»¶åˆæ˜¯ä¸åŒtopicçš„åˆ†éƒ¨ï¼Œæ‰€ä»¥å®é™…ä¸Šè§£å†³äº†ä¸€ä¹‰å¤šè¯çš„é—®é¢˜ï¼Œå³ä¸€ä¸ªæ„æ€å±äºä¸€ä¸ªtopicä½†å´å¯ä»¥ç”±å¾ˆå¤šä¸åŒçš„è¯è¡¨ç¤º
ç›¸è¾ƒä¸unigramæˆ–è€…ngraméƒ½åªèƒ½æ ¹æ®è¯è¯­æœ¬èº«çš„æ ·å­å»è®¡ç®—ç›¸ä¼¼åº¦ï¼Œè¦æ±‚use of overlapped wordsï¼Œæ‰€ä»¥ä¸èƒ½è§£å†³ä¸€ä¹‰å¤šè¯é—®é¢˜ã€‚